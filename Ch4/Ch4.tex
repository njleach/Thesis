{\onehalfspacing%
\begin{savequote}[8cm]
  Changes in many extreme weather and climate events have been observed since about 1950. Some of these changes have been linked to human influences ...
      \qauthor{--- IPCC, AR5, 2014}
\end{savequote}
    
\chapter{\label{ch4}Attribution with perturbed initial and boundary condition forecasts}

This chapter represents the culmination of my work regarding forecast-based approaches to attribution. I produce perturbed initial and boundary condition forecasts of the 2021 Pacific Northwest Heatwave, an unprecedented event that posed significant challenges to traditional approaches to attribution. I use these counterfactual forecasts to provide a more complete estimate of the human contribution to the heatwave than was possible in the previous chapter. 
{\small\paragraph{Author contributions:} This chapter is based on the following publication \footnote{with the author contributing as follows. Conceptualisation, Data curation, Formal analysis, Investigation, Methodology, Resources, Visualisation, Writing -- original draft and Writing --- Review \& Editing.} \par\vspace{1em}
\formatchref{Leach, N. J., Roberts, C. D., Heathcote, D., Mitchell, D. M., Thompson, V., Palmer, T. N., Weisheimer, A., \& Allen, M. R.}{2022}{Reliable heatwave attribution based on successful operational weather forecasts}{TBC}{in submission}{}{}{https://doi.org/10.21203/rs.3.rs-1868647/v1}}

\clearpage

\minitoc

\clearpage}

\section{Chapter open}\label{ch4:open}

  I now continue precisely from where I left off at the end of the previous chapter. At this point, I had demonstrated that a forecast-based approach was possible --- but only in the context of a very limited attribution to the direct effect of CO$_2$ alone. For such an approach to provide not just interesting, but useful information, I needed to work out how to provide a more complete estimate of the anthropogenic influence on specific weather events. Based on previous attribution work \citep{pall_anthropogenic_2011}, the key earth-system component I would need to consider was the ocean. Following this previous work, I planned to incorporate the impact of human influence on the ocean by perturbing the initial conditions of the forecast model. I also planned to continue using the same forecast model, ECMWF's IFS, as the previous chapter, both for consistency and due to the available computing resource. This presented a key challenge: while there is a significant quantity of literature on perturbed SST approaches to attribution \citep{stone_benchmark_2021}, the IFS is coupled, and I would therefore need to determine how to perturb the 3D ocean conditions, not just the surface. This technical challenge also presented an opportunity: perturbing the full depth of the ocean means that the resulting simulations are consistent with observed changes in ocean heat content, and do not contain any infinite sources or sinks of heat as is the case with the prescribed-SST simulations widely used in attribution. It also means that the impacts of cooler ocean temperatures on ocean-atmosphere interactions will be taken into account, further increasing the physical consistency with reality over prescribed-SST simulations. An important part of this chapter is therefore the methodology I developed with advice from Chris Roberts at ECMWF for producing counterfactual forecast initial conditions. An associated question I would have to answer would be whether any perturbations made (effectively `kicking' the model) would fundamentally affect the predictability of the event. This was something I discussed in the previous chapter, but it would become even more important here, since the perturbations applied here represent a much larger kick than only altering the CO$_2$ concentration.

  At the time when I was planning these simulations, the 2021 Pacific Northwest Heatwave had just occurred, presenting a very natural case study for us to apply this more complete forecast-based approach to, as conventional approaches had clearly been pushed to their limit with this event. Overall, the aim of this study was to demonstrate that we could provide a near-complete estimate of the human influence on this unprecedented event using a weather forecast model that was demonstrably able to simulate it.

  % I think this could be better
  % Following on from the previous chapter, the primary aim was to try and use a forecast-based approach to provide a more complete estimate of human influence on an individual extreme. Based on previous work \citep{pall_anthropogenic_2011}, the key component we needed to include was anthropogenic influence on the ocean --- in addition to the changes to atmospheric CO$_2$ concentration. Although there is a considerable body of literature concerning how to perturb sea surface temperatures in climate models to include this effect \citep{stone_benchmark_2021}, the model we used previously, and continued to use, is coupled, and therefore we needed a way to perturb not just the SSTs, but also the ocean subsurface. This technical challenged posed by the coupling also presented an opportunity, as it means that the resulting counterfactual forecasts are consistent with observed changes in ocean heat content (the primary energy sink for thermal energy accumulated in the earth system as a result of global warming), and do not contain any infinite sources or sinks of heat, as is the case in the prescribed-SST simulations used widely in attribution. We considered a number of different methods for imposing the ocean perturbations, including a nudged ocean spin-up simulation, but settled on arguably the simplest approach, which has been used previously by Chris Roberts at ECMWF for testing the impact of different ocean resolutions. At the time when we were planning these simulations, the 2021 Pacific Northwest Heatwave had just occurred, presenting a very natural case study for us to apply the forecast-based approach to, as conventional approaches had clearly been pushed to their limit with this event. The overall aim of our study was to demonstrate that we could provide a near-complete estimate of the human influence on this unprecedented event using a weather forecast model that was demonstrably able to simulate it.

\section{Abstract}\label{ch4:abstract}

  Extreme weather attribution, quantifying the role of human influence in specific weather events, is of interest to scientists, adaptation planners and the general public \cite{national_academies_of_sciences_engineering_and_medicine_attribution_2016}. However, the devastating 2021 Pacific Northwest heatwave challenged conventional statistical approaches to attribution due to the absence of similar events in the historical record, and model-based approaches due to poor representation of key causal processes in current climate models \cite{white_unprecedented_2022}. Here we use state-of-the-art operational medium-range and seasonal weather prediction systems, applied for the first time to this kind of climate question and unequivocally able to simulate the detailed physics of the heatwave in question, to show that human influence on the climate made this event at least 8 [2--30] times more likely to occur. Quantifying the absolute probability of such an unprecedented event is more challenging, but the length of the observational record suggests at least a multi-decade return-time in the current climate, with the likelihood doubling every 17 [10--50] years at the current rate of global warming. Our forecast-based approach synthesises the storyline approach, which examines human influence on the physical drivers of an event in a deterministic manner \cite{shepherd_common_2016}, and the probabilistic approach, which assesses how the frequency of a class of events has been affected by human influence \cite{stott_human_2004}. If developed as a routine service in a number of forecasting centres, it could provide reliable estimates of the changing probabilities of all extreme events that can be represented in forecast models, which is critical to supporting effective adaptation planning \cite{harrington_integrating_2022,mitchell_climate_2021}.

\section{Introduction}\label{ch4:intro}

  Although considerable progress has been made over the past decade in quantifying the impact of climate change on individual extreme weather events \cite{stott_human_2004,national_academies_of_sciences_engineering_and_medicine_attribution_2016}, challenges remain over the assessment of the most extreme events. Such events are particularly difficult to draw confident conclusions about due to the lack of historical analogues, and their often poor representation in the climate models normally used for event attribution. Two contrasting mainstream frameworks to event attribution have been developed: the storyline approach, which examines anthropogenic influence on the causal drivers of the extreme in question and is therefore highly conditioned on its specific characteristics \cite{trenberth_attribution_2015,shepherd_common_2016,hoerling_anatomy_2013}; and the probabilistic approach, which aims to determine how anthropogenic influence has affected the likelihood of events at least as extreme as the one in question \cite{philip_protocol_2020,pall_anthropogenic_2011}. 

  A key challenge for extreme event attribution is that we cannot make direct observations of a world without human influence on the climate, so all approaches must involve some kind of modelling, either statistical \cite{van_oldenborgh_how_2007} or dynamical \cite{pall_anthropogenic_2011}. Both face difficulties with the most extreme events, especially when considering the nonlinear processes that often drive unprecedented events. Statistical models used in conventional attribution can break down when faced with such events due to the lack of appropriately similar historical samples \cite{gessner_very_2021}, while numerical climate models generally used in attribution studies are typically coarse (O(100 km) horizontal resolution), and poorly represent important processes involved in the development of extreme weather events, such as blocking \cite{masato_winter_2013} and atmospheric rivers \cite{payne_evaluation_2015}. Even with a `perfect' model of the earth system, the unconditioned nature of the vast majority of climate model simulations used in attribution means that obtaining enough analogues of unprecedented events \cite{fischer_increasing_2021} to avoid the same issue faced by statistical modelling of the observational record requires very large ensembles, possibly beyond current computational limits \cite{leach_generating_2022}. Crucially, the role of climate change in an individual event may differ from that in other events of the same class due to the specific physical processes behind it \cite{palmer_nonlinear_1999,palmer_simple_2018}.

  The storyline framework overcomes some of these issues, and the risk of a false negative, by examining the impact of climate change on the causal drivers of an event deterministically. For instance, one might separate out the thermodynamic (typically high confidence in response to climate change and well-represented in numerical models) and dynamic (typically much lower confidence in response to climate change, and more poorly represented in numerical models) drivers of an event, for example by conditioning on the concurrent large scale atmospheric circulation. One approach for applying such conditioning is to `nudge' climate model simulations towards the large-scale flow observed during a particular extreme \cite{van_garderen_methodology_2021,benitez_july_2022}. The storyline approach does not, however, provide quantitative information about how climate change has affected the probability of the event in question, which is of interest to the general public and relevant to policymakers for adaptation planning.

  We propose a forecast-based approach that could synthesise the probabilistic and storyline frameworks to extreme event attribution \cite{leach_forecast-based_2021}. Although they belong to the same class of dynamical model and often share components \cite{roberts_climate_2018}, operational weather forecast models are typically run at much higher resolutions than climate models, improving their overall physical representation of extremes. They are validated for producing predictions that span the range of possible weather by the centres that produce them to a much higher degree than climate models, where other aspects are more important. In addition to this high level of explicit validation, using a model that has successfully predicted an event ensures that the model is able to accurately represent all the processes involved in the event in question, increasing the reliability of attribution statements based upon it \cite{palmer_simple_2018}. Stepping back through lead times allows for a robust storyline-like framing by examining how climate change has affected the causal drivers of the specific event within the limits of predictability. Probabilistic attribution can be performed using a reliable forecast ensemble, with the level of conditioning set by the lead time - the limiting case of long lead times is equivalent to a conventional unconditioned analysis. There has been some previous work into forecast-based attribution, using seasonal forecast models \cite{hope_contributors_2015,hope_what_2016,hope_determining_2019,wang_initialized_2021,hope_subseasonal_2022} and exploring the conceptual framework \cite{pall_diagnosing_2017,wehner_estimating_2019,tradowsky_toward_2022}. To our knowledge, however, this study is the first time that a complete forecast-based attribution has been carried out in a coupled operational forecast model at such a high resolution.

  In this study we use the coupled operational ECMWF model to analyse the Pacific Northwest heatwave, taking advantage of its successful predictions of this unprecedented event at leads of over a week. We perform counterfactual forecasts of the event by perturbing the initial and boundary conditions of the model in order to simulate how the heatwave might have emerged had it occurred in a cooler pre-industrial world, or a warmer future world. We then compare the counterfactual and operational forecasts to assess the impact of anthropogenic climate change on both the magnitude and probability-of-occurrence of the event. We believe that this forecast-based approach opens the door to not only a reliable and practical operational attribution system, but also to a robust way of generating projections of future weather explicitly referenced to the forecasts used already by adaptation planners \cite{hazeleger_tales_2015}.

\section{The Pacific Northwest heatwave}\label{ch4:heatwave}

  At the end of June 2021, a large fraction of the Pacific Northwest region of the US and Canada experienced unprecedented high temperatures, including the cities of Portland, Salem, Seattle and Vancouver (Figure \ref{fig4.1}). This heatwave (the `PNW heatwave') has been directly linked to many hundred excess deaths during and following it, making it the deadliest weather event on record for both Canada and Washington state \cite{henderson_analysis_2022}. The heatwave peak was observed between the 28th \& 30th June, though temperatures were still exceptionally high on the days immediately before and after this period \cite{menne_global_2012,menne_overview_2012}. Many local maximum temperature records were broken during this period, including the Canadian all-time record by a margin of 4.6 \textdegree{}C.

  Based on current understanding, the heatwave arose from an optimal combination of proximal drivers \cite{overland_causes_2021,lin_2021_2022,mo_anomalous_2022,white_unprecedented_2022}. Development of an omega block between the 23rd-27th coincided with the landfall of an atmospheric river (AR) on the 25th. Warm air was drawn up from the tropical West Pacific, heated diabatically through condensation in the river and then further heated adiabatically through subsidence: both the temperature and lapse rate at 500 hPa reached or approached record levels in the regions affected. This atmospheric heating was enhanced by soil moisture feedbacks \cite{thompson_2021_2022} and high insolation at the land surface during the hottest hours of the day (Figure \ref{fig4.2}). Given the unprecedented nature of the observed heatwave, any dynamical numerical model would need to capture all these processes, including the coupling between them, in order to produce an accurate representation of the event.
  
  Despite the observed temperatures lying far outside the historical record, the heatwave was well predicted by numerical weather forecast models such as from ECMWF at lead times of more than a week. The seasonal forecast from ECMWF captured one important aspect of the event: it predicted a thicker troposphere than average (measured by 500 hPa geopotential height) over the Pacific Northwest during the summer. A key change in the predictability of the exceptional temperatures occurred around June 21st, being the earliest point at which the penetration of the AR over land was well represented \cite{mo_anomalous_2022}. The success of these forecast models provides an opportunity to use them to examine the influence of anthropogenic climate change on the event as it actually occurred.

  \clearpage
  \begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{{Fig4.1}.png}
    \caption[Features and forecasts of the Pacific Northwest heatwave.]{\textbf{Features and forecasts of the Pacific Northwest heatwave. Top panel:} Surface temperature anomalies at the time of the peak heat during the heatwave within the region enclosed by 45--52 N, 119--123 W (indicated by the dotted rectangle). Solid black contours show the 500 hPa geopotential height anomaly averaged over 26-30th June 2021. Data are from ERA5 reanalysis \cite{hersbach_era5_2020}. \textbf{Inset:} timeseries of annual maximum temperatures for the same dotted region. \textbf{Bottom panels:} As above, but taken from the ensemble member within the forecast initialised on the date given above each panel that predicted the nearest temperature to the reanalysis within the dotted region.}
    \label{fig4.1}
  \end{figure}
  \clearpage

\section{Methods}\label{ch4:methods}

  \subsection*{Event definition}
  
    How the extreme event of interest is quantified - the event definition - is a key methodological decision that must be made in extreme event attribution studies. A significant amount of previous work has shown the impact of the event definition on the quantitative outcome of the analysis \cite{uhe_comparison_2016,kirchmeieryoung_importance_2019,angelil_nonlinearity_2018}. In this study we use a definition consistent with a previous attribution study of the PNW heatwave \cite{philip_rapid_2021} to allow for a comparison between our forecast-based approach and their probabilistic statistical and climate-model based approach.
  
    We first average maximum temperatures over the region enclosed by 45--52 N, 119--123 W (indicated by the dotted rectangles in Figures \ref{fig4.1} \& \ref{fig4.2}). For the event as observed in the ERA5 reanalysis \cite{hersbach_era5_2020} we then take the peak temperature recorded during the heatwave, which occurred at 00 UTC on 2021-06-29. For the event as simulated in the medium-range forecast ensemble members, we take the peak temperature that occurred between the 26-30th June, the period over which the heatwave occurred in reality. For the event as simulated in the seasonal forecast ensemble members, which we would not expect to predict the precise timing of the heatwave, we take the peak temperature over the full summer season. The differences between the event definitions of the medium-range and seasonal cases lead to the discrepancies in the climatologies shown in Figure \ref{fig4.3}.
  
  \subsection*{Experiment details}
  
    \paragraph*{Model details}
  
      The medium-range experiments we have performed use the version of the IFS EPS that was operational at the time of the PNW heatwave, CY47R2 \cite{noauthor_ifs_2020}. The forecast model atmosphere is run at a resolution of O640 ($\sim$18 km) and has 137 vertical levels. The atmosphere is coupled to a 0.25 degree wave model \cite{janssen_interaction_2004}, 0.25 degree sea ice model \cite{fichefet_sensitivity_1997}, LIM2, and 0.25 degree ocean model \cite{madec_nemo_2008}, NEMO v3.4, with 75 vertical levels (ORCA025Z75 configuration). We maintain the same number of ensemble members as the operational system, 51, throughout our experiments.
    
      The seasonal experiments are performed with ECMWF`s operational seasonal forecasting system, SEAS5 \cite{johnson_seas5_2019}. This uses IFS CY43R1 \cite{noauthor_ifs_2016} at a horizontal resolution of Tco319 ($\sim$36 km) with 91 vertical levels. The seasonal configuration of IFS CY43R1 is coupled to a 0.5 degree wave model, LIM2, and NEMO v3.4 in the ORCA025Z75 configuration. We maintain the same number of ensemble members as the operational system, 51, throughout our experiments.
  
    \paragraph*{Simulation setup}
  
    Our experiments all use the exact operational setup (model configuration and initial conditions) as their base. To this setup, we:
  
    \begin{enumerate}
      \item Change the CO2 concentrations used to a `pre-industrial' level of 285 ppm, and a `future' level of 615 ppm. These represent the same fractional change in opposite directions from the present-day concentration of 420 ppm used in the operational forecast system.
      \item Subtract (for the pre-industrial forecast) or add (for the future forecast) a perturbation of the estimated anthropogenic influence on the ocean state since the pre-industrial period from the initial conditions of the forecasts (through the ocean restart files). The estimation of this perturbation is described below. We use estimated perturbations for 3D temperature, SIC, and sea ice thickness.
      \item Check the sea ice fields for unphysical values. In the perturbed restarts, we ensure that SIC does not exceed 1 or subceed 0. We ensure that sea ice thickness does not subceed 0. Values outside these bounds are set to their nearest bound. Finally, we set sea ice thickness to 0 where SIC is 0, and vice versa.
      \item Modify ocean salinity such that in-situ ocean density is preserved following the 3D temperature perturbation as calculated using the equation of state from the forecast ocean model. The salinity compensation is achieved to machine precision using a simple gradient descent algorithm. The resulting coupled forecasts are thermodynamically consistent with the imposed ocean heat content anomalies without any adjustments to the initial ocean circulation, mixed layer depths, or horizontal pressure gradients. Importantly, and unlike uncoupled forecasts constrained by specified sea-surface temperatures, there are no infinite sources or sinks of heat in the resulting counterfactual forecasts. This approach is justifiable in shorter-range forecasts as there is no direct influence of salinity on the overlying atmosphere. This assumption may eventually break down at lead times comparable to ocean advective processes, for which there could be indirect feedbacks on the atmosphere associated with salinity-driven changes in the ocean state. Nevertheless, this approach works well for the medium-range and seasonal forecasts described in this study.
    \end{enumerate}
  
    The perturbations used are computed using an optimal fingerprint analysis \cite{hasselmann_optimal_1993,hasselmann_multi-pattern_1997,haustein_real-time_2017}. We first calculate the Anthropogenic Warming Index (AWI) using anthropogenic and natural radiative forcings from AR6 \cite{masson-delmotte_earths_2021} and the HadCRUT5 GMST dataset \cite{morice_updated_2021}. The AWI provides us with a plausible estimate of the fingerprint of anthropogenic influence on other climate variables \cite{hasselmann_optimal_1993}. For each perturbed variable, we then regress observed timeseries at each gridpoint onto the AWI, using the following data sources:
  
    \begin{itemize}
      \item Sea ice thickness: ORAS5 (1958:2019) \cite{zuo_ecmwf_2019}
      \item SIC: ORAS5 (1958:2019) \cite
      {zuo_ecmwf_2019}
      \item SST: HadISSTv1.1 (1870-2019) \cite{rayner_global_2003}
      \item Subsurface temperature: WOA18 (1950-2017) \cite{locarnini_world_2019}
    \end{itemize}
  
    We then scale the computed regression coefficients at each point by the change in AWI between the pre-industrial period of 1850-1900 and 2019 to produce our final estimated perturbations. The sea surface, and zonally and globally averaged temperature profiles are shown in Figure \ref{fig4.4}.
  
    Finally, we combine the sea surface and subsurface temperature perturbations. We did not use a subsurface temperature dataset in isolation since observations of the SST are considerably more abundant in the early 20th century than observations of subsurface temperatures, and since the temperatures at and near the surface are likely to be the most important for the medium-range forecasts performed, we leveraged the additional information contained in observed SST. We combine the two by relaxing the sea surface perturbation towards the subsurface perturbation using a relaxation depth scale of 60 m (the surface autocorrelation scale in WOA18).
  
    We note that estimation of the perturbation, and in particular the subsurface temperatures, is associated with considerable uncertainty due to the lack of observations in the pre-ARGO era \citep{argo_argo_2022,goldsworth_symmetric_2021}. Here we have used a single best-estimate perturbation due to constraints on the available computational resource, but to account for this uncertainty an ensemble of perturbations could be applied \cite{sparrow_attributing_2018}. A possible way in which such an ensemble could be derived would be to apply optimal fingerprinting to an ensemble of coupled climate models.
  
    \clearpage
    \begin{figure}[h]
      \centering
      \includegraphics[width=\textwidth]{{Fig4.S1}.png}
      \caption[The initial ocean state perturbation applied.]{\textbf{The initial ocean state perturbation applied. Left panel:} map of the surface temperature perturbation. \textbf{Top right panel:} map of zonally averaged temperature perturbations as a function of depth. \textbf{Bottom right panel:} globally averaged temperature perturbation as a function of depth. Note that the x-axis switches from a linear to logarithmic scale at a depth of 500 m.}
      \label{fig4.4}
    \end{figure}
    \clearpage
  
  \subsection*{Bias correction of seasonal forecast ensembles}
  
    Climate drift can be an issue in the use of coupled seasonal forecast models \cite{stockdale_coupled_1997}. We find a non-negligible drift in the daily maximum temperature SEAS5 forecast ensemble initialised in May over the PNW region. This drift results in a positive temperature bias that grows with lead time. Hence, using the raw model output in our analysis would overestimate the probability of the PNW heatwave. 
  
    To account for the drift, we perform a simple bias-correction procedure on the seasonal forecast ensembles, informed by comparing the SEAS5 hindcasts over 1981-2020 with ERA5 reanalysis data over 1950-2020 (using the full time period that data is available and excluding the year of the event, 2021). We do this in three steps:
    
    \begin{enumerate}
      \item Remove the attributable forced trend from both the reanalysis and hindcasts by regressing mean JJA daily maximum temperatures onto the AWI \cite{hasselmann_optimal_1993}.
      \item Remove the drift from these detrended hindcasts, estimated by averaging the hindcasts for each lead time over all years and ensemble members, subtracting this from the corresponding reanalysis average over all years, and then regressing this timeseries onto the (linear) lead times, producing a linearly lead-time dependent drift correction \cite{stockdale_coupled_1997}.
      \item The drift-corrected hindcasts still exhibit a positive bias during periods of extreme high temperatures. Hence, we finally remove the remaining mean bias in annual maximum temperatures in the hindcasts compared to reanalysis.
    \end{enumerate}
  
    We apply this bias correction procedure to both the seasonal hindcasts shown in Figure \ref{fig4.3} and used to estimate the return time of the event, and to the operational and perturbed seasonal forecasts of the 2021 summer. Figure \ref{fig4.5} shows the results of this bias correction procedure, following \citet{thompson_high_2017}.
  
    We note that validation of the bias correction procedure on the SEAS5 distribution of annual maximum temperatures (TXx) is challenging due to the unprecedented nature of the 2021 event. If we perform an analysis of the higher-order moments of the SEAS5 and `observed' (ERA5 reanalysis over 1950-2020) distributions of TXx \cite{thompson_high_2017}, we find that the bias-corrected ensemble tends to have larger values of higher-order moments than the observed timeseries. However, if the 2021 event is included in the observed distribution, then the opposite is found, due to the large impact of such an outlier on these moments. This sensitivity to inclusion / exclusion of the 2021 event, demonstrated in Figure \ref{fig4.5}, is why we have opted to perform a simple but physically motivated bias correction rather than a more complex statistical correction such as a quantile map.
  
    % \clearpage
    \begin{figure}[h]
      \centering
      \includegraphics[width=\textwidth]{{Fig4.S2}.pdf}
      \caption[Validation of the bias correction applied to the SEAS5 seasonal forecast simulations.]{\textbf{Validation of the bias correction applied to the SEAS5 seasonal forecast simulations}, following \citet{thompson_high_2017} Figure 2. \textbf{Left panel:} PDFs of summer maximum temperatures in detrended reanalysis, and raw and bias-corrected seasonal hindcasts. \textbf{Right panels:} CDFs of detrended proxy raw and bias-corrected seasonal hindcast timeseries mean, variance, skewness and kurtosis compared to reanalysis values. In all panels, we show reanalysis both including and excluding the 2021 PNW heatwave.}
      \label{fig4.5}
    \end{figure}
    \clearpage
  
  \subsection*{Statistical methodology}
  
    \paragraph*{Intensity changes}
  
      We calculate changes in intensity as the difference between the average of the nearest quintile of each ensemble to the event (in terms of peak temperatures). For the three longer leads, this is effectively the difference between the averages of the uppermost quintile of the two ensembles.
  
    \paragraph*{Risk changes}
  
      We calculate the relative risk (also known as the probability ratio) by first fitting either a GEV distribution to the full operational ensemble (for the shortest lead) or a straight line on a return-time diagram (i.e. an exponential tail) to the nearest quintile of either the operational ensemble (for the other two medium-range leads) or the model climatology (for the seasonal lead, since the tail of the operational ensemble lies considerably further below the event threshold than the tail of the much larger model climatology). We do this because while the shortest lead ensemble is well represented by a GEV distribution, the other three are not, and have generally heavier tails than estimated by likelihood-maximising GEV distributions. In these cases, where the event threshold lies in the extreme tail of the ensemble, the tail properties of the approximating distribution project considerably onto the estimated probability of the event. Hence, to avoid any undue assumptions on the tail shape, we fit a straight line on a return-time diagram such as Figure \ref{fig4.3} (assuming an exponential tail) to the nearest quintile. 
  
      After fitting an appropriate distribution, we then shift the location of this distribution by the estimated attributable warming. We then calculate the probability of observing an event at least as intense as the PNW heatwave (the dashed line in Figure \ref{fig4.3}) in the original distribution and the shifted distribution. The relative risk is the ratio of these two probabilities ($P_\text{current} / P_\text{shifted}$).
  
      Throughout this chapter, CIs are calculated using a 10,000 member non-parametric bootstrap with replacement.

\section{Forecast-based attribution}\label{ch4:attribution}

  The date at which we initialise our perturbed forecasts is a key choice that allows us to condition our attribution analysis on different synoptic drivers of the heatwave, which become predictable at different leads \cite{lin_2021_2022,mo_anomalous_2022}. The climate change response of drivers already present in the initial conditions is clearly not incorporated into our attribution results for each lead time due to this conditioning. Starting with the operational configurations of the ECMWF forecast model, we chose to focus on three medium-range and one seasonal forecast lead: 3 days, 7 days, 11 days and 2-4 months. These leads highlight the following aspects of the attribution: 

  \begin{itemize}
    \item 3 days (2021-06-26): a forecast very highly conditioned on the synoptic drivers of the event, with several key drivers prescribed in the initial conditions, and the rest forecast near perfectly. At this lead, our experiments could be considered analogous to a storyline attribution framing.
    \item 7 days (2021-06-22): a highly conditioned forecast, with most simulated processes mirroring reality closely. However, the shape and gradient reversal magnitude of the block shows considerable variation in this ensemble.
    \item 11 days (2021-06-18, depicted in Figure \ref{fig4.2}): while the exceptional thickness of the tropospheric block was well predicted in a large proportion of the ensemble, the shape and associated gradient reversal was only captured in a few members. The occurrence of the AR was well predicted, but its location and penetration over land less so, with most members predicting a more southerly landfall. The low soil moisture and cloud cover was well captured by the majority of the ensemble.
    \item 2--4 months (2021-05-01): a considerably less conditioned forecast. For this lead, we take the peak heat event over the whole summer period since we do not expect the forecast to predict the timing of the heatwave. Although the forecasts were unusually successful at predicting elevated geopotential height and temperatures over the summer in general, none of the peak heat events within individual ensemble members capture all of the detailed features of the PNW heatwave. At this lead, the ensemble can be viewed as being near-analogous to a high resolution unconditioned climate model simulation (though one that we know is able to represent the processes involved in the PNW heatwave accurately).
  \end{itemize}

  We then perturb the boundary and initial conditions of the operational forecast as described fully in the \hyperref[ch4:methods]{Methods}. First, we perturb the CO$_2$ concentrations in the atmosphere back to pre-industrial levels of 285 ppm, similar to \citet{leach_forecast-based_2021}. Then we remove a balanced estimate of anthropogenic change between pre-industrial and the present-day in surface and sub-surface ocean temperatures, SIC, and sea ice thickness \cite{locarnini_world_2019,rayner_global_2003,zuo_ecmwf_2019} from the initial state of the model. Perturbing the temperatures over the entire ocean depth means that we produce forecasts that are thermodynamically consistent with the changes in upper ocean heat content, in contrast to prescribed SST approaches \cite{massey_weatherhome-development_2015,ciavarella_upgrade_2018}. We do not alter the land-surface, noting the high uncertainties in past trends for indicators such as soil moisture in this region \cite{masson-delmotte_water_2021,masson-delmotte_changing_2021,masson-delmotte_atlas_2021}. Removing anthropogenic influence from the ocean state and reducing CO$_2$ levels produces a counterfactual `pre-industrial' forecast; we also apply identical perturbations in the opposite direction to produce a `future' forecast, in which the ocean state and CO$_2$ levels of 615 ppm correspond to approximately twice the level of global warming experienced at the present-day.

  We find that despite the large impulse applied by the perturbed initial state upon forecast initialisation, the predictability of the heatwave is remarkably stable. The key synoptic drivers of the heatwave present in the original operational forecast remain intact. There are some changes consistent with the canonical response to global warming, including a thickening of the lower troposphere \cite{christidis_changes_2015} and increased tropospheric water vapour \cite{allen_constraints_2002} in the future forecast; and vice-versa in the pre-industrial forecast. As such, the perturbations have not altered the forecasts in such a way that they produce `different' weather, and we can compare our forecasts to estimate the influence of anthropogenic global warming on the Pacific Northwest heatwave. This is consistent with \citet{leach_forecast-based_2021}, but is not guaranteed to be the case for every weather event.

  This experiment design is consistent with the perturbed CO$_2$ experiments of \citeauthor{leach_forecast-based_2021} in another important respect: the adjustment to the new `pre-industrial' or `future' climate state occurs continually throughout the forecast. This adjustment typically means that as the lead time increases, the estimated attributable influence on the heatwave also increases. Interplay between dynamical noise and attributable signal in the forecasts, both of which increase with the lead time (short leads correspond to more confident but smaller attributable impacts and vice-versa) is discussed further in \citeauthor{leach_forecast-based_2021}. The adjustment means that any attributable impacts estimated directly from the forecasts are lower-bounds on the true anthropogenic impact. However, we find that attributable impacts on the heatwave are approximately linear with the coincidental global land warming level within the perturbed forecasts across the range of leads explored, shown in Figure \ref{fig4.S7} and consistent with \citet{seneviratne_regional_2020}. Hence, in addition to the impacts estimated directly from the perturbed forecasts, we also present impacts scaled to the global warming level within the forecast at the time of the heatwave.

  \clearpage
  \begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{{Fig4.2}.png}
    \caption[Drivers of the PNW heatwave and their predictability in the 11-day lead forecast.]{\textbf{Drivers of the PNW heatwave and their predictability in the forecast initialised 2021-06-18 (11 days). Top row:} temperature anomaly fields for the PNW heatwave in the ensemble mean, nearest member and reanalysis. Solid black contours indicate 500 hPa geopotential height anomalies and stippling indicates regions with total cloud cover greater than 25\%. \textbf{Second row:} mean total column water vapour anomalies on the 25th June. The study region of 45--52 N, 119--123 W, over which fields are aggregated into timeseries, is indicated by the dotted rectangle. Anomalies shown are calculated relative to the 2001--2020 period. \textbf{Bottom three rows:} timeseries of daily maximum temperatures, total column water vapour and total cloud cover in each forecast ensemble member. The solid black line shows the reanalysis timeseries and the thick solid line shows the nearest member. The colour of each line indicates the rank of that ensemble member in terms of the peak temperature simulated during the heatwave period (dark grey = coolest, dark red = warmest). The solid black bar on the time axis of each panel indicates the averaging period used for the total column water vapour maps.}
    \label{fig4.2}
  \end{figure}
  \clearpage

  \clearpage
  \begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{{Fig4.S7}.pdf}
    \caption[Linearity of local and global responses to imposed perturbations.]{\textbf{Linearity of local and global responses to imposed perturbations.} Each dot shows the ensemble mean difference between the pre-industrial and future forecasts. The y-axis represents the difference in heatwave intensity, and the x-axis represents the difference in global land warming level at the time of the heatwave. Colours indicate forecast initialisation date and marker styles indicate perturbation applied. `IC-observational' use the observation-based perturbations used in the results presented; `IC-CMIP6' use initial condition perturbations derived from the CMCC-CM2-HR4 coupled climate model historical simulation; and `CO$_2$-only' use CO$_2$ boundary condition perturbations only as in \citet{leach_forecast-based_2021}.}
    \label{fig4.S7}
  \end{figure}
  \clearpage

  \subsection{Results}\label{ch4:results}

  The results of our forecast-based approach can be presented either as the attributable human influence on the intensity of the heatwave or the probability of the heatwave. We find that the intensity of the heatwave is reduced in the pre-industrial forecasts for all lead times (Figure \ref{fig4.3}). Due to the continual adjustment of the forecasts to the initial condition perturbations, the attributable influence on the heatwave peak temperature, estimated as half the difference between the pre-industrial and future forecasts to maximise the signal-to-noise ratio, increases as the lead time increases, ranging from 0.28 \textdegree{}C [0.25--0.33]\footnote{Numbers in square brackets [] represent a likely CI (17--83\%) throughout this chapter.} using the 3-day lead to 0.7 \textdegree{}C [0.35--1.0] using the seasonal forecast. We account for the continual adjustment of the perturbed forecasts by scaling the attributable influence by the ratio of the coinciding global land warming level to the observed present-day level of 1.6 \textdegree{}C \cite{osborn_land_2021}. This results in a best-estimate attributable impact on the heatwave intensity of 1.3 \textdegree{}C [0.5--1.9] for a current level of anthropogenic warming of 1.25 \textdegree{}C \cite{haustein_real-time_2017}. This accounts for approximately 20\% of the 7 \textdegree{}C 2021 anomaly over previous annual maxima.

  We quantify the attributable change in probability due to anthropogenic global warming using relative risk \cite{stone_end--end_2005}, estimating the probability of observing an extreme at least as extreme as the observed 2021 heatwave using an appropriate extreme-value or tail distribution, and then shifting this distribution by the attributable change in intensity for each lead time. As with the heatwave intensity, the relative risk tends to increase with forecast lead time due to the adjustment to the initial conditions. Our results are consistent with a linear relationship between log probabilities and the coinciding global land warming level. If we account for this adjustment by scaling log probabilities by the current global land warming level of 1.6 \textdegree{}C, we find a best-estimate relative risk of a factor of 8 times [2--30] considering all lead times, or analogously a fraction of attributable risk of 0.9 [0.5--0.97]. 

  Using the current rate of global warming over land \cite{haustein_real-time_2017} we can further estimate that the probability of observing an event at least as warm as the 2021 Pacific Northwest heatwave is doubling every 17 [10--50] years, and will continue to do so unless the rate of global warming decreases. Given the length of the historical record and our estimated change in probability over this period, such an event would be associated with a multi-decade to multi-century return period at the present-day, thus making this doubling time very relevant for adaptation planning. 

  % \clearpage
    \begin{figure}[h]
      \centering
      \includegraphics[width=\textwidth]{{Fig4.3}.pdf}
      \caption[Return-time diagram of the PNW heatwave in the operational and counterfactual forecast ensembles.]{\textbf{Return-time diagram of the PNW heatwave in the operational and counterfactual forecast ensembles.} Each panel shows ensembles initialised at the lead given above the panel. Red, grey and blue dots indicate empirical return-time plots based on the ensemble members of the future, current and pre-industrial forecasts. The dashed grey line shows the temperature threshold observed during the PNW heatwave. The black dots indicate the recent climatology, based on detrended ERA5 reanalysis over 1950--2020. The solid grey line indicates the model climatology estimated using detrended hindcasts over 2001--2020 for the medium-range forecast, and using detrended and bias-corrected hindcasts over 1981--2020 for the seasonal forecast. The arrow in the left panel indicates, for illustration, the displacement along the log-scaled x-axis equivalent to a 5-fold increase in occurrence probability.}
      \label{fig4.3}
    \end{figure}
    \clearpage

\section{Discussion}\label{ch4:discussion}

  The results presented here provide strong evidence of the impact of climate change on a specific extreme event, based on a model that has been demonstrated unequivocally to be able to simulate the event in question through a successful medium-range forecast. Our estimates of relative risk are lower than previous climate model-based estimates \cite{philip_rapid_2021}, albeit are not entirely incompatible within the context of the associated uncertainties and the fact that our estimates represent a lower bound on the impact of climate change on the heatwave \cite[as was the case in][]{leach_forecast-based_2021}. The primary reason is that our model (unlike a typical climate model) is capable of simulating the multiple physical factors that contributed to the heatwave that occurred, so we are not relying on extrapolation of distributions from physically dissimilar events. Moreover, our imposed perturbations do not include the total sum of human influence on the climate. It is known that land surface feedbacks are important in the development of extreme heatwaves \cite{fischer_contribution_2007}, and is plausible that if we had removed the influence of anthropogenic climate change from the initial land state in addition to the ocean state, the resulting attribution statement might have been stronger.

  Nevertheless, we argue that the forecast-based methodology presented here represents an important advance in both attribution in general, and operational attribution. Rather than relying on multiple lines of evidence that would each be unsatisfactory in isolation, here we have presented a single adequate line. The key to the adequacy of the result is the ability of the model used to represent the event in question, demonstrated through successful prediction. This not only means that we have increased confidence in the model's response to external forcing \cite{palmer_simple_2018,palmer_nonlinear_1999}, but also that the analysis is a genuine attribution of the specific event that occurred (rather than a mixture of events that share some characteristic like extreme temperatures, but differ in other important meteorological aspects). Forecast-based attribution provides many of the advantages of the storyline approach to attribution, but can still be used to provide quantitative estimates of the changing probability of extreme events with climate change. The use of an operational weather forecast model demonstrates how this approach could be easily adapted to provide an operational system for attribution in real-time \cite[or potentially even in advance,][]{wang_initialized_2021}. Such a system would involve re-running operational forecasts with perturbed initial and boundary conditions as in the counterfactual forecasts we have presented here \cite{wehner_operational_2022}.

  There remain a number of ways in which the forecast-based approach explored here could be further developed. Firstly, analysis of the forecasts would be simplified if they were started from balanced states, rather than continually adjusting to the new initial conditions throughout the forecast. This could be done by either including additional perturbations to the initial conditions \cite[ie. to the land-surface and atmospheric states,][]{wang_initialized_2021,reed_attribution_2022,wehner_operational_2022}, or possibly by perturbing the initial state using the operational data-assimilation itself. Secondly, while here we have chosen to use the exact setup used operationally by ECMWF, the uncertainty of forecast-based attribution statements could be reduced by increasing the ensemble size \cite[we note that 51 members is a relatively small ensemble in the context of traditional attribution-specific experiments,][]{massey_weatherhome-development_2015,ciavarella_upgrade_2018}, particularly for the longer, relatively less-conditioned lead times.

  The focus of this study was on the attribution question, but this forecast-based methodology could be applied to produce projections designed to inform climate change adaptation. Analogous to our `future' counterfactual forecast, which we used here check the linearity of the climate change response, perturbations consistent with specific levels of global warming could be applied in order to, for example, simulate specific extreme events as if they occurred in a world of 2 \textdegree{}C. Such simulations of potential future extremes could be used to test the limits of regional adaptation in a targeted manner based on impactful events that have already occurred \cite{hazeleger_tales_2015}, complementing other approaches such as \citet{leach_generating_2022}, which was designed to produce a rich set of different extreme events rather than specific `grey-swan' type events.

  \paragraph*{Concluding remarks}\label{ch4:remarks}

    In this study, we have used a numerical weather forecast-based approach to determine the contribution of human influence to a specific unprecedented extreme event. We used a state-of-the-art coupled operational weather forecast model that was unequivocally able to simulate the event in question, demonstrated by a successful prediction. Our perturbed initial condition approach maintains consistency with the measured changes in upper ocean heat content, unlike many previous approaches. We view this forecast-based approach as synthesising the storyline and probabilistic approaches to event attribution, keeping the event specificity of the storyline approach while still providing meaningful estimates of the changing risk of the extreme in question. Given that it is increasingly clear that we need to go beyond the meteorology of event attribution, and into the societal impacts \cite{mitchell_climate_2021,mitchell_increased_2022}, we suggest that our approach would be particularly well-placed to advance this agenda, especially in the context of extremes in a future climate.

\section{Chapter close}\label{ch4:close}

  In this chapter, the key takeaway is that we were able to use a relatively simple methodology to produce counterfactual forecasts of an individual extreme weather event, which we can then use to estimate the anthropogenic component of that event. This methodology is very similar to that used by \citet{pall_anthropogenic_2011}, and is based on perturbing the forecast initial conditions, but has been adapted to allow coupled weather forecast models to be used. There remain a number of outstanding issues with the approach we have taken, most notably whether we should be --- and how we should go about --- perturbing the initial atmospheric and land-surface states too. In terms of remaining scientific questions, a particularly interesting avenue would be to explore how atmospheric predictability changes in counterfactual forecasts. We have been surprised at how consistent the predictability of our case study extreme events is, even when `kicking' the model as hard as we have done. It would be very interesting, and important for forecast-based approaches in general, to determine if there are particular situations where predictability breaks down in the counterfactual worlds. Unfortunately, I cannot address these questions within the scope of this thesis, but I discuss them further, including how they might be addressed in the future, in the thesis \hyperref[discussion]{discussion}.

  Although the clear immediate application of the approach described in this chapter would be an operational attribution service, I am particularly interested in exploring how the same approach could be used for climate projection of extreme events. There are additional uncertainties associated with projection, including the socioeconomic pathway taken, and the pattern of ocean warming, but such a forecast-based approach to projection would still confer many of the advantages I have argued that it does for attribution \citep[e.g.][]{hazeleger_tales_2015}. This shift in focus to climate projection fits in with the following \hyperref[ch5]{chapter}, in which I explore a novel methodology for generating a rich variety of samples of future extreme weather that could be used for adaptation planning. I suggest that climate projection using counterfactual forecasts could complement the approach taken in \hyperref[ch5]{chapter 5} by providing understanding and information about specific damaging extremes. This would be a natural direction for future work; as I discuss further in the \hyperref[discussion]{discussion}.